# ISSUE: 時空間座標 (x,y,z,t) + 多次元目的変数 f のワークフロー拡張（非テーブル/フィールドデータ対応）

> 位置づけ: **将来検討（今の改良スコープ外）**

## 背景 / 問題意識

- 現在のプロジェクトは「テーブルデータ（行=サンプル）× 単一目的変数（基本）」を前提に、`dataset_id -> preprocess -> training-summary -> inference` の導線を最適化しています。
- 今後、データ種がテーブルではなく **時空間座標に紐づくフィールド値**で、目的変数が **多次元**（例: f がベクトル、複数物理量、複数チャネル等）のケースに拡張したい。
- ただしこの拡張は、前処理・モデル・評価・可視化・推論I/Oが大きく変わり、Pipeline のタスク数も増える可能性が高い。

## 想定データ（前提）

### データの形（概念）

- 1レコードは「座標 + 時刻 + 目的変数」を持つ:
  - 入力（座標/時刻）: `(x, y, z, t)`（次元は可変）
  - 出力（目的変数）: `f`（多次元）
- フォーマットは共通だが、ケースにより次元の組合せが変わる:
  - 空間1次元: `x` のみ（`y,z` は定数/欠損/未使用）
  - 空間2次元: `x,y`
  - 空間3次元: `x,y,z`
  - 時間軸あり/なし: `t` がある or 定数/欠損/未使用
- 「対象変数の変化がない」場合は **定数**または**空欄**で表現される想定（= 次元の有無の判定ルールが必要）。

### 重要な分岐（データ構造）

- 点群（不規則サンプル）か、格子（規則グリッド）か、メッシュ/グラフか
- 1点に対して `f` がスカラー/ベクトルか、あるいは `f` 自体が「周波数/高さ方向」などの軸を持つか
- データ量（行数）が大きい（時空間で爆発しやすい）ため、ファイル形式・分割・ストリーミングが重要

## この拡張で起きる“本質的に変わる点”

- 前処理が「欠損/カテゴリ/スケーリング」中心から、**時空間特徴量化**（距離・近傍・ラグ・周期・埋め込み等）や、**モード分解/低次元化**（POD/SVD/DMD/FFT 等）へ広がる
- モデルが「表形式回帰/分類」中心から、**多出力回帰**・**時系列**・**空間構造モデル**（CNN/GNN/GP/Transformer 等）へ拡張する
- 評価指標が「1値の metric」から、**多出力×時空間**（点ごと/スライス/統合ノルム）へ拡張する
- 可視化が「散布図/残差」中心から、**スライス/ヒートマップ/時系列/アニメーション**等が必須になる
- 推論I/Oが「1行入力→1値」から、**範囲指定（領域/期間）→フィールド出力**や、**再構成（低次元→元空間）**を含む

## To-Be案（“何を重視するか”別のワークフロー像）

### 案A: 既存思想の踏襲（互換性/最短導線を最優先）

**狙い**

- 既存のテーブルAutoMLの枠（Phase構造/拡張ポイント/ClearML UI方針）を最大限維持し、導入コストを最小化する。

**ワークフロー（例）**

- dataset_register（必要なら） -> preprocess（必要なら） -> training-summary（親+学習子） -> inference（mode）
- “非テーブル”でも、内部は「行=観測点（座標/時刻）」に **フラット化**し、`(x,y,z,t)` を特徴量、`f` を多出力ターゲットとして扱う。

**決めるべき方針（要議論）**

- 多出力の扱い: `f` を `f1..fk` に展開して独立に学習するか、マルチタスクとして同時に学習するか
- 次元の有無判定: `y/z/t` が “定数/欠損/未使用” のときのルール（UI表示・リーク対策にも影響）
- 分割戦略: ランダムCVで良いか、時間/空間ホールドアウトを必須にするか（リーク）
- 評価の集約: 多出力を 1つの primary metric にどう落とすか（平均/最大/重み付き/物理量優先）

**必要な開発項目（例）**

- Dataset契約拡張: 次元メタ（存在する軸、単位、座標系、範囲）を `schema.json/manifest.json` に格納
- 多出力用の metric / leaderboard 表示（per-target + aggregated）
- 可視化の最小セット（スライス/時系列を “1–2枚” で意思決定できる形に）
- inference の I/O 仕様拡張（入力が点/複数点/範囲指定を許すか）

**メリット**

- “dataset_id だけで回る” 既存ユーザージャーニーを維持しやすい
- 拡張ポイント（registry/workflow/clearml_logging）を崩しにくい

**デメリット/限界**

- 空間/時間の構造を捨てるため、性能/汎化が頭打ちになりやすい
- 大規模データで “フラット化” がメモリ/速度ボトルネックになりやすい

---

### 案B: 構造を活かす（性能/汎化を優先、ワークフローを拡張）

**狙い**

- 時空間構造（近傍・連続性・周期性）を明示的に利用し、性能/汎化を上げる。

**ワークフロー（例）**

- dataset_register -> preprocess（次元判定/整形/分割/特徴量化） -> train_parent（モデルごと） -> inference
- preprocess 内（または独立タスク）で以下を許容:
  - グリッド化/補間/リサンプリング（格子モデル用）
  - 時系列ウィンドウ化（sequence-to-one / seq2seq）
  - 座標埋め込み（Fourier features, positional encoding 等）

**決めるべき方針（要議論）**

- 対応モデル範囲: まずは “点群×多出力回帰” を強化するのか、グリッドCNN/GNNまで行くのか
- データ構造の正規形: 内部表現を point / grid / graph のどれに寄せるか（複数併存も可だが運用が複雑）
- 推論API: 単点推論だけで良いか、領域/期間のバッチ推論・可視化まで含めるか

**必要な開発項目（例）**

- `core/data` に “時空間データローダ/バッチャ” の導入（parquet/zarr/netCDF 等も要検討）
- `core/preprocessing` に “軸推論/グリッド化/特徴量化” を追加（bundleで再現可能に）
- `registry/models.py` に “spatiotemporal 対応モデル” の追加枠（依存関係・GPU要否の扱い）
- `workflow/*/visualization.py` に “スライス/ヒートマップ/時系列” の標準プロットを定義

**メリット**

- データの構造を使えるため、性能/汎化が伸びやすい

**デメリット/リスク**

- 依存ライブラリ/GPU/データ形式が増え、保守と環境構築が重くなる
- Pipeline のタスクが増え、UIが複雑になりやすい（ユーザー導線の再設計が必要）

---

### 案C: 低次元化（モード分解/Reduced-Order Model を優先）

**狙い**

- 空間次元が高い/データが巨大な場合に、モード分解で低次元表現へ圧縮し、学習・推論コストを下げる。

**ワークフロー（例）**

- dataset_register
- preprocess（次元判定/クリーニング）  
- **decompose（POD/SVD/DMD 等）**: フィールド `f` を係数 `c`（低次元）へ  
- train（`(x,y,z,t)->c` または `(t)->c` 等）  
- inference: `c` を予測し **reconstruct** で元の `f` を復元

**決めるべき方針（要議論）**

- 分解手法の優先順位: POD/SVD, DMD, FFT/波レット、NMF…どれから始めるか
- “どの軸を圧縮するか”: 空間だけ/時間も含める/変数（チャネル）も含める
- モード数（rank）の選定基準: 再構成誤差/累積寄与率/計算制約
- 再構成を inference の必須機能とするか（係数だけ出す運用もあり得る）

**必要な開発項目（例）**

- preprocess bundle に「分解器（basis/mean/normalization）」を含め、再構成まで再現可能にする
- 新しい phase（例: `decompose` / `reconstruct`）を workflow に追加するか、preprocess/inference に内包するかの設計
- 評価指標: 係数誤差 + 再構成誤差（空間ノルム/最大誤差/物理的制約）
- 可視化: basis（モード形状）、再構成誤差マップ、寄与率曲線

**メリット**

- 巨大データでも学習・推論が回りやすい
- “モデルが学ぶ対象” がシンプルになり、最適化や探索がしやすい場合がある

**デメリット/リスク**

- 分解手法の選択や前提（線形性・定常性等）により、適用できる領域が限定される
- 実装・説明が難しく、非専門ユーザー向け導線の設計が必要

## 共通で決めるべき方針（議論ポイント）

### 1) Dataset契約（フォーマット / メタデータ）

- 何を “正” とするか: point / grid / graph のどれを基本にするか
- 形式: parquet/zarr/netCDF など（サイズとストリーミング要件次第）
- 軸メタ: 使用軸、単位、座標系、範囲、欠損/定数の扱い
- “対象変数の変化がない” の定義と、UI/学習/評価での扱い（学習から除外? 定数として残す?）

### 2) 分割・リーク対策

- 時間ホールドアウト（未来予測）を標準にするか
- 空間ホールドアウト（未観測領域）を標準にするか
- “同一点の別時刻” を train/test に跨がせるか（許容/禁止）

### 3) 評価・ランキング（training-summary の primary metric）

- 多出力をどう集約するか（平均/最大/重み付き/優先ターゲット）
- 時空間をどう集約するか（全点平均、領域別、時間帯別、最大誤差等）

### 4) 推論I/O（ユーザーが何を入力し、何を得るか）

- 単点: `(x,y,z,t)` を入れて `f` を返す
- バッチ: 点群/期間/領域を入力して `f` の表/ファイルを返す
- 返却形式: csv/parquet/zarr/netCDF（サイズ要件次第）
- 可視化の標準出力: 何を inference の Plots に必須とするか

### 5) Pipeline とタスク増加の扱い

- “追加されるタスク” を phase として分離するか（decompose等）、既存 phase 内のサブステップにするか
- ClearML UI 上の見通しをどう維持するか（親=要約、子=詳細、Plotsのナンバリング等）

## 判断の単位（受け入れ条件案）

- [ ] dataset_id を入力して end-to-end で動く（少なくとも案Aの最短導線）
- [ ] training-summary で「どのモデルを推論に使うか」が迷わず決まる（多出力でも）
- [ ] inference で “ユーザーが求める粒度” の出力が artifacts/plots に残る（単点/領域/期間）
- [ ] データ契約（schema/manifest/bundle）が再現性を担保し、train/infer で齟齬が出ない
- [ ] Pipeline のタスク構造が追跡可能（run_id/tags/命名が崩れない）

## 次アクション（将来タスク案）

1. “まず対応する最小ユースケース” を 1つ決める（例: 2D+time、点群、f=3チャネル）
2. 案A/B/C のどれを最初に採用するか決める（もしくは案Aを前提に段階的にB/Cへ）
3. Dataset契約（ファイル形式 + schema/manifest + 欠損/定数ルール）を文書化
4. 評価・primary metric の集約ルールを決める（leaderboard が壊れない）
5. 必須Plots/Artifacts を定義（非専門でも理解できる最小セット）

## 関連リンク（プロジェクト内）

- `docs/DEV_GUIDE.md`
- `docs/REFORM_PLAN.md`（または `Agents.md` に同内容あり）

